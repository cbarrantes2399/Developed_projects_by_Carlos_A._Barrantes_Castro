{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681be972",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad40792",
   "metadata": {},
   "source": [
    "# MNIST template\n",
    "\n",
    "## Tarea 4\n",
    "\n",
    "Este archivo permite cargar el set de datos MNIST para ser usado con scikit-learn.\n",
    "\n",
    "Puede usarlo como base para entrenar sus modelos, la selección de modelos.  No olvide guardar sus modelos en un archivo para utilizar los mejores de ellos en ``predict_digit.ipynb``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b69848",
   "metadata": {},
   "source": [
    "MNIST es un set de datos bastante utilizado, y existen múltiples posibilidades de cargarlo en programas de Python.\n",
    "\n",
    "- Usando ``fetch_openml`` de ``sckit-learn`` es una opción pero tiene en algunas versiones el problema de que baja todo el conjunto de internet cada vez que se ejecuta el programa, lo que no lo hace viable.\n",
    "- Usando el paquete ``python-mnist``, que no existe en las distribuciones de conda\n",
    "- Usando el paquete ``mnist``\n",
    "- Usando ``pandas``\n",
    "\n",
    "Aquí usaremos la versión que usa el paquete ``mnist``, para evitar dependencias adicionales a bibliotecas grandes.\n",
    "\n",
    "Dicho paquete carga los datos como un tensor de 60000x28x28, es decir, 60000 imágenes de 28x28 dimensiones.  Cada pixel es de tipo entero sin signo de 8 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si le falta la biblioteca 'mnist' y usa Anaconda:\n",
    "#!conda install mnist\n",
    "\n",
    "# o cualquier otra distribución de Python:\n",
    "#!pip install mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c10fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic=time.time()\n",
    "\n",
    "# Asegure que el directorio de datos existe.\n",
    "datadir='./mnist_data/'\n",
    "Path(datadir).mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "# temporary_dir es una función que retorna el directorio temporal;\n",
    "mnist.temporary_dir = lambda: datadir\n",
    "\n",
    "# Prepare el codificador 'one-hot'\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# La primera vez, esto puede tardar unos segundos a minutos por tener\n",
    "# que bajar los datos originales de internet.\n",
    "# Después de eso debería ser rápido.\n",
    "\n",
    "# Prepare los datos de entrenamiento\n",
    "train_images = mnist.train_images() # Esto es un tensor m x 28 x 28\n",
    "train_labels = mnist.train_labels().astype(int)\n",
    "train_ohelab = enc.fit_transform(train_labels.reshape(-1,1)).toarray() # labels one-hot encoded\n",
    "\n",
    "m,h,w=train_images.shape\n",
    "train_data = train_images.reshape((m,w*h)).astype(float)/255 # Esto es una matrix de m x 784\n",
    "\n",
    "# Prepare los datos de validación\n",
    "val_images = mnist.test_images() # Esto es un tensor de m x 28 x 28\n",
    "val_labels = mnist.test_labels().astype(int)\n",
    "val_ohelab = enc.transform(val_labels.reshape(-1,1)).toarray()\n",
    "\n",
    "vm,vh,vw=val_images.shape\n",
    "val_data = val_images.reshape((vm,vw*vh)).astype(float)/255 # Esto es una matrix de m x 784\n",
    "\n",
    "\n",
    "toc=time.time()-tic\n",
    "print(\"Tardó: {0} s\".format(toc))\n",
    "\n",
    "print(\"Entrenamiento: {0} datos de {1}x{2} dimensiones\".format(m,h,w))\n",
    "print(\"Validación   : {0} datos de {1}x{2} dimensiones\".format(vm,vh,vw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5948a1",
   "metadata": {},
   "source": [
    "A este punto, se cuenta con la siguiente información para poder entrenar:\n",
    "\n",
    "- train_data: arreglo de 60000 datos de 784 dimensiones\n",
    "- train_label: vector de 60000 etiquetas como enteros entre 0 y 9\n",
    "- train_ohelab: arreglo de 60000x10 con la codificación de las etiquetas _one-hot_\n",
    "- val_data: arreglo de 10000 datos de 784 dimensiones\n",
    "- val_label: vector de 10000 etiquetas como enteros entre 0 y 9\n",
    "- val_ohelab: arreglo de 10000x10 con la codificación de las etiquetas _one-hot_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8373f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestre algunas muestras\n",
    "samples = np.random.choice(np.arange(m),4,replace=False)\n",
    "\n",
    "for i in samples:\n",
    "    plt.imshow(train_data[i].reshape((28,28)),cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Etiqueta entera:\",train_labels[i])\n",
    "    print(\"         one-hot:\",train_ohelab[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34efbf8f",
   "metadata": {},
   "source": [
    "## Entrenar/seleccionar modelos\n",
    "\n",
    "A continuación usted debe entrenar y seleccionar los modelos, y guardar el mejor de ellos para cada tipo (SVM, RDF, kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06adbf28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
